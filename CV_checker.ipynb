{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf546217-7553-4f63-8d2f-f0d2931db676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465d95b7-632a-4f01-bc10-6a6a93b792ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"cv.pdf\"\n",
    "doc = pymupdf.open(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120081f6-169e-42a5-a002-2a6af2228a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piotr Piotrowski\n",
      "Python Developer\n",
      "Computer Science\n",
      "Uniwersytet Radomski im. Kazimierza Pułaskiego\n",
      "01.10.2021 - 30.04.2025\n",
      "Bachelor's degree in engineering\n",
      "ABOUT ME\n",
      "Phone number: 722797143\n",
      " Email: piotr15q@op.pl\n",
      "I am passionate about Machine Learning with\n",
      "experience in Python and a hands-on approach to\n",
      "implementing ML models. My interests include\n",
      "creating Machine Learning models and deploying\n",
      "them in a production environment. I am looking for\n",
      "growth opportunities in the area of Artificial\n",
      "Intelligence.\n",
      "Skills\n",
      "Programming: Python, C# (Unity)\n",
      "Machine Learning & Data Science:\n",
      "PyTorch, NumPy, Pandas, Matplotlib,\n",
      "Scikit-learn\n",
      "Databases: SQL\n",
      "Version Control: Git\n",
      "EDUCATION\n",
      "PROJECTS\n",
      "Additional information:\n",
      "driving license: category B\n",
      "Polish: Native\n",
      "English: B2\n",
      "Ability to work under time pressure\n",
      "Ability to work in a team\n",
      "Problem solving skills\n",
      "Ability to search for information\n",
      "Analysis and critical thinking\n",
      "My Portfolio Page (in progress)\n",
      "I am creating a portfolio site to showcase my\n",
      "projects. The site is under development, but\n",
      "the image classifier is already fully\n",
      "implemented. I am currently working on\n",
      "another project to put on the site.\n",
      "Dog & Cat Classification\n",
      "I created from scratch a convolutional neural\n",
      "network (CNN) that classifies photos as dog or\n",
      "cat with ~87% accuracy. The model has been\n",
      "implemented on my portfolio site (ongoing\n",
      "project).\n",
      "Contact:\n",
      "Interests:\n",
      "Programming\n",
      "Artificial intelligence\n",
      "Technologies\n",
      "Sport\n",
      "Travelling\n",
      "Automotive\n",
      "I consent to the processing of my personal data by Commerzbank for\n",
      "the purpose of recruiting for the position I have applied for.\n",
      "I https://github.com/piotr15q/DogVsCat_Classification\n",
      "https://github.com/piotr15q/Portfolio_Page\n"
     ]
    }
   ],
   "source": [
    "for page in doc:\n",
    "    text = page.get_text()\n",
    "    print(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32740b97-e95e-4538-bdf1-72f16bdd6b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "200205e8-3bba-4188-8796-d5d567ca463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here’s a poem about Hugging Face, aiming to capture its essence – a hub for AI, a community, and a vibrant ecosystem:\n",
      "\n",
      "---\n",
      "\n",
      "The cloud expands, a digital hue,\n",
      "Hugging Face, a vision fresh and new.\n",
      "A platform built on models, bold and bright,\n",
      "Connecting minds, a collaborative light.\n",
      "\n",
      "From transformers to vision's grace,\n",
      "A vast repository, a welcoming space.\n",
      "Datasets shared, a boundless store,\n",
      "For researchers and builders, evermore.\n",
      "\n",
      "With datasets diverse, a welcoming plea,\n",
      "For all to learn, and collaborate, free.\n",
      "Spaces bloom with notebooks, clear and clean,\n",
      "Where code is woven, a vibrant scene.\n",
      "\n",
      "From text to images, a language untold,\n",
      "The models flourish, brave and bold.\n",
      "From fine-tuning models, intricate and deep,\n",
      "To building chatbots, secrets they keep.\n",
      "\n",
      "A community thrives, a helping hand,\n",
      "To guide the learners, across the land.\n",
      "With tutorials, guides, and steady cheer,\n",
      "Hugging Face empowers, year after year.\n",
      "\n",
      "So step inside, and explore the flow,\n",
      "Of AI’s potential, watch the knowledge grow.\n",
      "Hugging Face, a beacon shining bright\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BitsAndBytesConfig, Gemma3ForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"google/gemma-3-1b-it\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "model = Gemma3ForCausalLM.from_pretrained(\n",
    "    model_id, quantization_config=quantization_config\n",
    ").eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"You are a helpful assistant.\"}]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": \"Write a poem on Hugging Face, the company\"}]\n",
    "    },\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=True,  # Tokenizacja od razu\n",
    "    return_dict=True,\n",
    "    return_tensors=\"pt\",  # teraz chcemy zwykły tekst, nie tokeny\n",
    ").to(model.device)\n",
    "\n",
    "#inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=256)\n",
    "\n",
    "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "response_only = output_text.split(\"model\\n\")[-1].strip()\n",
    "print(response_only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febee811-36eb-44b0-8d06-4586d455864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_only\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb15b8d-09fe-46de-989b-cc02bd63d335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"user\\nYou are a helpful assistant.\\n\\nWrite a poem on Hugging Face, the company\\nmodel\\nOkay, here's a poem about Hugging Face, aiming to capture its essence and impact:\\n\\n**The Algorithm's Heart**\\n\\nIn realms of data, vast and deep,\\nWhere models slumber, secrets sleep,\\nA digital haven starts to bloom,\\nHugging Face, dispelling gloom.\\n\\nFrom transformers sleek and bright,\\nTo datasets shining, pure and light,\\nA platform built for open code,\\nWhere knowledge freely is bestowed.\\n\\nResearchers and builders rise,\\nWith models crafted, reaching skies,\\nFrom NLP’s grace to vision’s art,\\nA collaborative, beating heart.\\n\\nWith datasets diverse and wide,\\nAnd tools to help, side by side,\\nYou simplify the learning quest,\\nAnd put the power to the test.\\n\\nSo raise a glass to this bright space,\\nWhere innovation finds its place,\\nHugging Face, a guiding hand,\\nBuilding the future, across the land! \\n\\n---\\n\\nWould you like me to:\\n\\n*   Try a different style (e.g., more concise, more evocative)?\\n*   Focus on a specific aspect of Hugging Face (e.g., the community, a particular model type)?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].replace(\"<bos>\", \"\").replace(\"<end_of_turn>\", \"\").replace(\"<start_of_turn>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11359129-b78f-4817-990b-81234dd57063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e93c3-f04e-4a1a-be17-375601d8fc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a91e918-b558-4123-8b1d-cf57d7e1c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1459c-18cb-433b-8f84-a1a613443623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b73a5a-6e38-4f6d-8b4e-c7c92c9af1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffdd72-2586-4cf8-82ab-8515d3a608a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679b1b5-09ec-41bf-a02c-654542b2be84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a46fb-af9e-4911-956a-7f781112af67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e182af-1b0e-41eb-a582-228c86f3aa73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd80ee-97a4-4d11-a4e9-9e9259e6615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3deb641-aa1e-42c3-a2e6-8142a7ce43a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a1b0c-ae67-4f4e-9ab2-14e00366f0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87ed2f-a0c9-4199-800b-c7e673053eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f33df1b-9eea-48df-8532-85bea320fbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e2bfe-9ee1-43a3-9ad8-7be52d49aa94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22961c-da77-4b7e-b6d8-31fbc95180f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5c652-81c7-4180-bf40-ce9e9a2d5cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
